# QUIC DoS Detection — Project Summary

**Student:** Safaa  
**Date:** February 2026  
**Status:** Complete - Evaluation Done

---

## Executive Summary

This project detects Denial-of-Service attacks against QUIC servers using **flow-level anomaly detection**. Rather than detecting attack traffic by its protocol signature, the approach trains an autoencoder exclusively on benign traffic and flags deviations from learned normal behavior. This makes detection robust to attack variations without requiring labeled attack samples.

The core contribution is a **realistic degradation dataset** generated by overwhelming a QUIC server with high-rate connection attempts, combined with empirical statistical proof that this degradation is measurable at the flow level — even in handshakes that technically completed.

**Current Progress:**
- ✅ Research and methodology finalized
- ✅ Traffic generation scripts developed and validated
- ✅ Network testbed configured (VM + WSL bridged network)
- ✅ Dataset generated — 159,420 benign / 14,375 malicious flows
- ✅ Statistical validation complete (Welch t-test + Cohen's d)
- ✅ Feature extraction pipeline complete
- ✅ Autoencoder trained and evaluated — AUC 0.9998, 100% malicious SF detection
- ✅ Baseline comparison (Isolation Forest) complete — AUC 0.9971
- ✅ Ablation study complete

---

## What Has Been Done

### 1. Research & Methodology Design ✅

**Key findings from literature and protocol analysis:**
- QUIC integrates TLS 1.3 into its handshake — each connection attempt requires cryptographic key derivation, making the handshake CPU-intensive
- Existing QUIC security datasets are scarce and do not model gradual degradation
- Detecting only incomplete handshakes (S0 state) misses the degradation signal in completed-but-stressed handshakes
- Unsupervised detection (autoencoder on benign) generalizes better than supervised classifiers trained on specific attack signatures

**Research gap addressed:** No existing high-quality QUIC DoS dataset captures the realistic mixed-state degradation (S0 + degraded SF) caused by server resource exhaustion.

---

### 2. Network Testbed Configuration ✅

```
┌─────────────────────┐              ┌─────────────────────┐
│   VirtualBox VM     │              │    WSL / Windows    │
│   Ubuntu 24.04      │              │    Client + Attack  │
│                     │              │                     │
│   QUIC Server       │◄────────────►│  Traffic Generator  │
│   Port 4433 (UDP)   │  Bridged     │  quic_traffic_      │
│   quic_server.py    │  1–5ms RTT   │  generator.py       │
│                     │              │                     │
│   tcpdump capture   │              │  quic_dos_          │
│                     │              │  realistic.py       │
└─────────────────────┘              └─────────────────────┘
       VM IP: 192.168.1.147                Port: 4433
```

**Why this setup is critical — the latency problem:**

| Setup | RTT | S0 Rate | Attack Signature |
|-------|-----|---------|-----------------|
| Localhost (same machine) | < 0.1ms | ~27% | ❌ Too weak for ML |
| VM bridged network | 1–5ms | 53–60% | ✅ Realistic degradation |

At sub-millisecond latency, the server responds to nearly every Initial packet before the attacker's connection context times out — producing mostly SF states indistinguishable from benign. The 1–5ms VM network delay introduces the right amount of server response lag for resource exhaustion to manifest as incomplete handshakes.

**Network configuration:**
- VM IP: 192.168.1.147
- Server port: 4433 (UDP/QUIC)
- Network mode: VirtualBox Bridged Adapter
- RTT: 1–5ms (verified with ping)

---

### 3. Traffic Generation ✅

#### Benign Traffic — `quic_traffic_generator.py`

Simulates realistic user browsing sessions over HTTP/3:

| Parameter | Value |
|-----------|-------|
| Session rate | 2 sessions/second (Poisson-distributed) |
| Total sessions | ~200,000 |
| Duration per session | 1–10 seconds (randomized) |
| Requests per session | 1–5 HTTP/3 GET requests (randomized) |
| wait_connected | `True` — waits for full handshake |
| Generation time | ~30 hours |

Each session makes realistic requests to paths like `/`, `/index.html`, `/api/data`, `/health`. Sessions close normally → nearly 100% SF state.

#### Malicious Traffic — `quic_dos_realistic.py`

Simulates high-rate connection attempt flooding:

| Parameter | Value |
|-----------|-------|
| Attack rate | 10,000 connections/second |
| Total attacks dispatched | 20,000 |
| Duration | 10 minutes |
| wait_connected | `False` — does not wait for handshake |
| Per-connection delay | 1ms (`asyncio.sleep(0.001)`) |
| Inter-attack distribution | Exponential (`random.expovariate(rate)`) |
| Generation time | ~10 minutes |

Each attack sends a valid QUIC Initial packet. The connection is abandoned after 1ms — the server receives the packet and begins processing but cannot respond to all of them at this rate.

#### Resulting Dataset

```
Benign flows:    159,420  (100% SF — 52 natural S0 outliers, < 0.03%)
Malicious flows:  14,375  (59.7% S0 / 40.3% SF)
                 ───────
Total:           173,795
```

---

### 4. Statistical Validation ✅

Performed by `statistical_analysis.py` using Welch's t-test (appropriate for unequal group sizes) and Cohen's d effect size.

#### Comparison 1: Benign (All) vs Malicious (All)

| Feature | Benign Mean | Malicious Mean | Cohen's d | Effect |
|---------|-------------|----------------|-----------|--------|
| orig_pkts | 13.45 | 2.78 | 2.52 | **LARGE** |
| resp_pkts | 11.07 | 1.11 | 2.57 | **LARGE** |
| PACKETS_TOTAL | 24.52 | 3.89 | 2.57 | **LARGE** |
| BYTES_TOTAL | 4312.32 | 2567.97 | 2.39 | **LARGE** |
| ROUNDTRIPS | 11.07 | 1.03 | 2.60 | **LARGE** |
| ASYMMETRY | 0.104 | 0.646 | -3.97 | **LARGE** |
| PPI | 3.07 | 248.16 | -3.11 | **LARGE** |

All p-values < 1e-50. Every key feature shows large effect size separation.

#### Comparison 2: Benign SF vs Malicious SF

This is the critical validation — proving that **completed** handshakes under attack still carry anomaly signal:

| Feature | Benign SF Mean | Malicious SF Mean | Cohen's d | Effect |
|---------|----------------|-------------------|-----------|--------|
| orig_pkts | 13.45 | 3.25 | 2.36 | **LARGE** |
| resp_pkts | 11.07 | 2.76 | 2.11 | **LARGE** |
| PACKETS_TOTAL | 24.52 | 6.01 | 2.25 | **LARGE** |
| ROUNDTRIPS | 11.07 | 2.56 | 2.16 | **LARGE** |
| duration | 6.09s | 13.63s | -1.49 | **LARGE** |
| BYTES_TOTAL | 4313.48 | 4093.00 | 0.35 | small |
| ASYMMETRY | 0.104 | 0.121 | -0.30 | small |

Malicious SF flows have roughly **one-quarter the packet exchanges** of benign SF flows. The longer duration reflects server queuing delay under load. This validates labeling degraded-but-completed handshakes as malicious.

#### Comparison 3: Benign SF vs Malicious S0

| Feature | Benign SF Mean | Malicious S0 Mean | Cohen's d | Effect |
|---------|----------------|-------------------|-----------|--------|
| orig_pkts | 13.45 | 2.47 | 2.56 | **LARGE** |
| resp_pkts | 11.07 | 0.00 | 2.84 | **LARGE** |
| ROUNDTRIPS | 11.07 | 0.00 | 2.84 | **LARGE** |
| ASYMMETRY | 0.104 | 1.000 | -19.46 | **LARGE** |
| PPI | 3.07 | 414.04 | -7.58 | **LARGE** |
| BYTES_TOTAL | 4313.48 | 1538.55 | 5.03 | **LARGE** |

S0 flows have zero reverse packets by definition (no server response) — perfect asymmetry and extreme PPI. These are the cleanest signal in the dataset.

---

### 5. Feature Engineering & ML Preprocessing ✅

#### Extraction (`extract_features.py`)

Features extracted from Zeek `conn.log`. No handcrafted DoS indicators included.

**19 features going into the ML pipeline:**

| Category | Features |
|----------|---------|
| Packet counts | PACKETS_FWD, PACKETS_REV, PACKETS_TOTAL |
| Byte counts | BYTES_FWD, BYTES_REV, BYTES_TOTAL |
| Duration | DURATION |
| Rate | PPS_FWD, PPS_REV, BPS_FWD, BPS_REV |
| Directional ratios | FWD_BWD_PKT_RATIO, FWD_BWD_BYTE_RATIO, ASYMMETRY |
| Bidirectionality | BIDIRECTIONAL_PAIRS, ROUNDTRIPS_PER_SEC |
| Packet size | MEAN_PKT_SIZE_FWD, MEAN_PKT_SIZE_REV |
| Timing | TIME_PER_PKT_FWD |

State features (`IS_COMPLETE`, `IS_INCOMPLETE`, `IS_RESET`, `IS_REJECTED`) extracted for analysis but excluded from training — direct label proxies.

#### Preprocessing Pipeline (`DOS_Detection.ipynb`)

**Step 1 — Log transform (`log1p`)** applied to 9 heavy-tailed features:
`PPS_FWD`, `PPS_REV`, `BPS_FWD`, `BPS_REV`, `FWD_BWD_PKT_RATIO`, `FWD_BWD_BYTE_RATIO`, `BYTES_TOTAL`, `BYTES_FWD`, `BYTES_REV`

Rationale: S0 flows have extreme PPS values (mean 414 pkts/sec vs benign 3 pkts/sec). Log transform reduces this skew without discarding the signal.

**Step 2 — Variance filtering** (`VarianceThreshold(1e-6)`): no features dropped (all carry variance).

**Step 3 — Correlation filtering** (threshold > 0.95): removes one from each highly correlated pair.

| Dropped feature | Correlated with |
|----------------|----------------|
| PACKETS_REV | PACKETS_FWD |
| PACKETS_TOTAL | PACKETS_FWD |
| BYTES_TOTAL | BYTES_FWD |
| PPS_REV | PPS_FWD |
| BPS_REV | BPS_FWD |
| BIDIRECTIONAL_PAIRS | ROUNDTRIPS_PER_SEC |

**Result: 13 final features** passed to the autoencoder.

**Step 4 — Scaling**: RobustScaler fitted on benign training set only (median/IQR normalization — robust to extreme values in malicious flows at test time).

**All features are flow-level** (not packet-level):
- ✅ Compatible with real-world NetFlow/IPFIX exports
- ✅ Lightweight and scalable
- ✅ Privacy-preserving — no payload inspection

---

### 6. Labeling Strategy ✅

All flows generated during malicious traffic windows are labeled **Malicious**, including completed handshakes (SF).

**Justification on two independent grounds:**

1. **Causal:** Completed handshakes during a flooding attack actively consume server CPU (TLS key derivation), memory, and connection table entries. They are part of the attack's load — not background benign traffic that happened to coincide.

2. **Empirical:** Statistical testing (Comparison 2 above) shows large Cohen's d effect sizes for packet counts and roundtrips between benign SF and malicious SF. These flows carry measurable anomaly signal and would contribute positively to detection if labeled correctly.

This is validated directly by the model results: the autoencoder achieves **100% detection on malicious SF flows** at the 95th percentile threshold — meaning even the "easy-looking" completed handshakes are correctly flagged.

Labeling only S0 flows as malicious would:
- Undercount the attack's impact by ~40%
- Discard valid training signal from degraded SF flows
- Misrepresent the actual threat model

---

## Model Results ✅

### Autoencoder Performance

**Architecture:** Input(13) → Dense(128) → Dense(64) → Dense(4, bottleneck) → Dense(64) → Dense(128) → Output(13)  
**Training:** Benign only, 60/20/20 split, RobustScaler, Adam lr=1e-3, EarlyStopping patience=5

| Metric | Value |
|--------|-------|
| **AUC-ROC** | **0.9998** |
| **Malicious SF detection rate** | **100%** |
| Operating threshold | 95th percentile of benign test error |
| FPR at operating threshold | 5% |

### Threshold Sensitivity

| Percentile | FPR | TPR |
|------------|-----|-----|
| 90th | 10.0% | 100% |
| **95th** ← operating point | **5.0%** | **100%** |
| 97th | 3.0% | 100% |
| 99th | 1.0% | 96.3% |

The model achieves perfect TPR down to the 97th percentile threshold, confirming that malicious flows sit well above the benign reconstruction error distribution — not just marginally above.

### Baseline Comparison

| Model | AUC-ROC |
|-------|---------|
| **Autoencoder (this work)** | **0.9998** |
| Isolation Forest | 0.9971 |

The autoencoder outperforms Isolation Forest by 0.003 AUC points. Both models use the same 13-feature set and RobustScaler preprocessing. The Isolation Forest used `n_estimators=200`, `contamination=0.05`.

### Ablation Study

Each feature group was removed in turn. AUC remained above 0.9995 in all cases:

| Removed group | Features removed | AUC | Mal SF Detection |
|---------------|-----------------|-----|-----------------|
| — (full model) | — | 0.9998 | 100% |
| counts | PACKETS_FWD, BYTES_FWD, BYTES_REV | 0.9997 | 100% |
| rates | PPS_FWD, BPS_FWD | 0.9996 | 100% |
| ratios | FWD_BWD_PKT_RATIO, FWD_BWD_BYTE_RATIO, ASYMMETRY, (MEAN_PKT_SIZE_*) | 0.9997 | 100% |
| bidirectional | ROUNDTRIPS_PER_SEC | 0.9999 | 100% |
| timing | TIME_PER_PKT_FWD, DURATION | 0.9996 | 100% |

**Interpretation:** No single feature group is a critical failure point. The degradation signal is distributed across all categories — an attacker cannot evade detection by manipulating one dimension of their traffic profile. This reflects the breadth of statistical impact that resource-exhaustion flooding has on flows.

---

